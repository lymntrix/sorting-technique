{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-9343ee7d0bb5>, line 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-9343ee7d0bb5>\"\u001b[0;36m, line \u001b[0;32m80\u001b[0m\n\u001b[0;31m    \"\"\"See if target appears in nums\"\"\"\u001b[0m\n\u001b[0m                                       \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Logarithms\n",
    "How to think about them, especially in programming interviews and algorithm design\n",
    "What logarithm even means\n",
    "\n",
    "Here's what a logarithm is asking:\n",
    "\n",
    "\"What power must we raise this base to, in order to get this answer?\"\n",
    "\n",
    "So if we say:\n",
    "log⁡10100 \\log_{10}{100} log10​100\n",
    "\n",
    "The 10 is called the base (makes sense—it's on the bottom). Think of the 100 as the \"answer.\" It's what we're taking the log of. So this expression would be pronounced \"log base 10 of 100.\"\n",
    "\n",
    "And all it means is, \"What power do we need to raise this base (101010) to, to get this answer (100100100)?\"\n",
    "10x=100 10^x = 100 10x=100\n",
    "\n",
    "What xxx gets us our result of 100100100? The answer is 222:\n",
    "102=100 10^2 = 100 102=100\n",
    "\n",
    "So we can say:\n",
    "log⁡10100=2 \\log_{10}{100} = 2 log10​100=2\n",
    "\n",
    "The \"answer\" part could be surrounded by parentheses, or not. So we can say log⁡10(100)\\log_{10}{(100)}log10​(100) or log⁡10100\\log_{10}{100}log10​100. Either one's fine.\n",
    "What logarithms are used for\n",
    "\n",
    "The main thing we use logarithms for is solving for xxx when xxx is in an exponent.\n",
    "\n",
    "So if we wanted to solve this:\n",
    "10x=100 10^x = 100 10x=100\n",
    "\n",
    "We need to bring the xxx down from the exponent somehow. And logarithms give us a trick for doing that.\n",
    "\n",
    "We take the log⁡10\\log_{10}log10​ of both sides (we can do this—the two sides of the equation are still equal):\n",
    "log⁡1010x=log⁡10100 \\log_{10}{10^x} = \\log_{10}{100} log10​10x=log10​100\n",
    "\n",
    "Now the left-hand side is asking, \"what power must we raise 101010 to in order to get 10x10^x10x?\" The answer, of course, is xxx. So we can simplify that whole left side to just \"xxx\":\n",
    "x=log⁡10100 x = \\log_{10}{100} x=log10​100\n",
    "\n",
    "We've pulled the xxx down from the exponent!\n",
    "\n",
    "Now we just have to evaluate the right side. What power do we have to raise 101010 to in order to get 100100100? The answer is still 222.\n",
    "x=2 x = 2 x=2\n",
    "\n",
    "That's how we use logarithms to pull a variable down from an exponent.\n",
    "Logarithm rules\n",
    "\n",
    "These are helpful if you're trying to do some algebra stuff with logs.\n",
    "\n",
    "Simplification: log⁡b(bx)=x\\log_{b}{(b^x)} = xlogb​(bx)=x . . . Useful for bringing a variable down from an exponent.\n",
    "\n",
    "Multiplication: log⁡b(x∗y)=log⁡b(x)+log⁡b(y)\\log_{b}{(x*y)} = \\log_{b}{(x)} + \\log_{b}{(y)}logb​(x∗y)=logb​(x)+logb​(y)\n",
    "\n",
    "Division: log⁡b(x/y)=log⁡b(x)−log⁡b(y)\\log_{b}{(x/y)} = \\log_{b}{(x)} - \\log_{b}{(y)}logb​(x/y)=logb​(x)−logb​(y)\n",
    "\n",
    "Powers: log⁡b(xy)=y∗log⁡b(x)\\log_{b}{(x^y)} = y * \\log_{b}{(x)}logb​(xy)=y∗logb​(x)\n",
    "\n",
    "Change of base: log⁡b(x)=log⁡c(x)log⁡c(b)\\log_{b}{(x)} = \\frac{\\log_{c}{(x)} }{\\log_{c}{(b)} }logb​(x)=logc​(b)logc​(x)​ . . . Useful for changing the base of a logarithm from bbb to ccc.\n",
    "Where logs come up in algorithms and interviews\n",
    "\n",
    "\"How many times must we double 1 before we get to nnn\" is a question we often ask ourselves in computer science. Or, equivalently, \"How many times must we divide nnn in half in order to get back down to 1?\"\n",
    "\n",
    "Can you see how those are the same question? We're just going in different directions! From nnn to 1 by dividing by 2, or from 1 to nnn by multiplying by 2. Either way, it's the same number of times that we have to do it.\n",
    "\n",
    "The answer to both of these questions is log⁡2n\\log_{2}{n}log2​n.\n",
    "\n",
    "It's okay if it's not obvious yet why that's true. We'll derive it with some examples.\n",
    "Logarithms in binary search (ex. 1)\n",
    "\n",
    "This comes up in the time cost of binary search, which is an algorithm for finding a target number in a sorted list. The process goes like this:\n",
    "\n",
    "    Start with the middle number: is it bigger or smaller than our target number? Since the list is sorted, this tells us if the target would be in the left half or the right half of our list.\n",
    "    We've effectively divided the problem in half. We can \"rule out\" the whole half of the list that we know doesn't contain the target number.\n",
    "    Repeat the same approach (of starting in the middle) on the new half-size problem. Then do it again and again, until we either find the number or \"rule out\" the whole set.\n",
    "\n",
    "In code:\n",
    "\n",
    "  def binary_search(target, nums):\n",
    "    \"\"\"See if target appears in nums\"\"\"\n",
    "    # We think of floor_index and ceiling_index as \"walls\" around\n",
    "    # the possible positions of our target so by -1 below we mean\n",
    "    # to start our wall \"to the left\" of the 0th index\n",
    "    # (we *don't* mean \"the last index\")\n",
    "    floor_index = -1\n",
    "    ceiling_index = len(nums)\n",
    "\n",
    "    # If there isn't at least 1 index between floor and ceiling,\n",
    "    # we've run out of guesses and the number must not be present\n",
    "    while floor_index + 1 < ceiling_index:\n",
    "        # Find the index ~halfway between the floor and ceiling\n",
    "        # We use integer division, so we'll never get a \"half index\"\n",
    "        distance = ceiling_index - floor_index\n",
    "        half_distance = distance / 2\n",
    "        guess_index = floor_index + half_distance\n",
    "\n",
    "        guess_value = nums[guess_index]\n",
    "        if guess_value == target:\n",
    "            return True\n",
    "\n",
    "        if guess_value > target:\n",
    "            # Target is to the left, so move ceiling to the left\n",
    "            ceiling_index = guess_index\n",
    "        else:\n",
    "            # Target is to the right, so move floor to the right\n",
    "            floor_index = guess_index\n",
    "\n",
    "    return False\n",
    "\n",
    "So what's the time cost of binary search? The only non-constant part of our time cost is the number of times our while loop runs. Each step of our while loop cuts the range (dictated by floor_index and ceiling_index) in half, until our range has just one element left.\n",
    "\n",
    "So the question is, \"how many times must we divide our original list size (nnn) in half until we get down to 1?\"\n",
    "n∗12∗12∗12∗12∗...=1 n * \\frac{1}{2} * \\frac{1}{2} * \\frac{1}{2} * \\frac{1}{2} * ... = 1 n∗21​∗21​∗21​∗21​∗...=1\n",
    "\n",
    "How many 12\\frac{1}{2}21​'s are there? We don't know yet, but we can call that number xxx:\n",
    "n∗(12)x=1 n * (\\frac{1}{2})^x = 1 n∗(21​)x=1\n",
    "\n",
    "Now we solve for xxx:\n",
    "n∗1x2x=1 n * \\frac{1^x}{2^x} = 1 n∗2x1x​=1 n∗12x=1 n * \\frac{1}{2^x} = 1 n∗2x1​=1 n2x=1 \\frac{n}{2^x} = 1 2xn​=1 n=2x n = 2^x n=2x\n",
    "\n",
    "Now to get the xxx out of that exponent! We'll use the same trick as last time.\n",
    "\n",
    "Take the log⁡2\\log_{2}log2​ of both sides...\n",
    "log⁡2n=log⁡22x \\log_{2}{n} = \\log_{2}{2^x} log2​n=log2​2x\n",
    "\n",
    "The right hand side asks, \"what power must we raise 222 to, to get 2x2^x2x?\" Well, that's just xxx.\n",
    "log⁡2n=x \\log_{2}{n} = x log2​n=x\n",
    "\n",
    "So there it is. The total time cost of binary search is O(log⁡2n)O(\\log_{2}{n})O(log2​n).\n",
    "Logarithms in sorting (ex. 2)\n",
    "\n",
    "Sorting costs O(nlog⁡2n)O(n\\log_{2}{n})O(nlog2​n) time in general. More specifically, O(nlog⁡2n)O(n\\log_{2}{n})O(nlog2​n) is the best worst-case runtime we can get for sorting.\n",
    "\n",
    "That's our best runtime for comparison-based sorting. If we can tightly bound the range of possible numbers in our list, we can use a hash map do it in O(n)O(n)O(n) time with counting sort.\n",
    "\n",
    "The easiest way to see why is to look at merge sort. In merge sort, the idea is to divide the list in half, sort the two halves, and then merge the two sorted halves into one sorted whole. But how do we sort the two halves? Well, we divide them in half, sort them, and merge the sorted halves...and so on.\n",
    "\n",
    "  def merge_sort(list_to_sort):\n",
    "    # Base case: lists with fewer than 2 elements are sorted\n",
    "    if len(list_to_sort) < 2:\n",
    "        return list_to_sort\n",
    "\n",
    "    # Step 1: divide the list in half\n",
    "    # We use integer division, so we'll never get a \"half index\"\n",
    "    mid_index = len(list_to_sort) / 2\n",
    "    left  = list_to_sort[:mid_index]\n",
    "    right = list_to_sort[mid_index:]\n",
    "\n",
    "    # Step 2: sort each half\n",
    "    sorted_left  = merge_sort(left)\n",
    "    sorted_right = merge_sort(right)\n",
    "\n",
    "    # Step 3: merge the sorted halves\n",
    "    sorted_list = []\n",
    "    current_index_left = 0\n",
    "    current_index_right = 0\n",
    "\n",
    "    # sortedLeft's first element comes next\n",
    "    # if it's less than sortedRight's first\n",
    "    # element or if sortedRight is exhausted\n",
    "    while len(sorted_list) < len(left) + len(right):\n",
    "        if ((current_index_left < len(left)) and\n",
    "                (current_index_right == len(right) or\n",
    "                 sorted_left[current_index_left] < sorted_right[current_index_right])):\n",
    "            sorted_list.append(sorted_left[current_index_left])\n",
    "            current_index_left += 1\n",
    "        else:\n",
    "            sorted_list.append(sorted_right[current_index_right])\n",
    "            current_index_right += 1\n",
    "    return sorted_list\n",
    "\n",
    "So what's our total time cost? O(nlog⁡2n)O(n\\log_{2}{n})O(nlog2​n). The log⁡2n\\log_{2}{n}log2​n comes from the number of times we have to cut nnn in half to get down to sublists of just 1 element (our base case). The additional nnn comes from the time cost of merging all nnn items together each time we merge two sorted sublists.\n",
    "Logarithms in binary trees (ex. 3)\n",
    "\n",
    "In a binary tree, each node has two or fewer children.\n",
    "A tree represented by circles connected with lines. The root node is on top, and connects to 2 children below it. Each of those children connect to 2 children below them, which all connect to their own 2 children, which all connect to their own 2 children.\n",
    "\n",
    "The tree above is special because each \"level\" or \"tier\" of the tree is full. There aren't any gaps. We call such a tree \"perfect.\"\n",
    "\n",
    "One question we might ask is, if there are nnn nodes in total , what's the tree's height (hhh)? In other words, how many levels does the tree have?\n",
    "\n",
    "If we count the number of nodes on each level, we can notice that it successively doubles as we go:\n",
    "A binary tree with 5 rows of nodes. The root node is on top, and every node has 2 children in the row below. Each row is labelled with the number of nodes in the row, which doubles from the top down: 1, 2, 4, 8, 16.\n",
    "\n",
    "That brings back our refrain, \"how many times must we double 1 to get to nnn.\" But this time, we're not doubling 1 to get to nnn; nnn is the total number of nodes in the tree. We're doubling 1 until we get to . . . the number of nodes on the last level of the tree.\n",
    "\n",
    "How many nodes does the last level have? Look back at the diagram above.\n",
    "\n",
    "The last level has about half of the total number of nodes on the tree. If you add up the number of nodes on all the levels except the last one, you get about the number of nodes on the last level—1 less.\n",
    "1+2+4+8=15 1 + 2 + 4 + 8 = 15 1+2+4+8=15\n",
    "\n",
    "The exact formula for the number of nodes on the last level is:\n",
    "n+12 \\frac{n+1}{2} 2n+1​\n",
    "\n",
    "Where does the +1 come from?\n",
    "\n",
    "The number of nodes in our perfect binary tree is always odd. We know this because the first level always has 1 node, and the other levels always have an even number of nodes. Adding a bunch of even numbers always gives us an even number, and adding 1 to that result always gives us an odd number.\n",
    "\n",
    "Taking half of an odd number gives us a fraction. So if the last level had exactly half of our nnn nodes, it would have to have a \"half-node.\" But that's not a thing.\n",
    "\n",
    "Instead, it has the \"rounded up\" version of half of our odd nnn nodes. In other words, it has the exact half of the one-greater-and-thus-even number of nodes n+1n+1n+1. Hence n+12\\frac{n+1}{2}2n+1​\n",
    "\n",
    "So our height (hhh) is the same as \"the number of times we have to double 1 to get to n+12\\frac{n+1}{2}2n+1​.\" So we can phrase this as a logarithm:\n",
    "h≈log⁡2(n+12) h \\approx \\log_{2}{(\\frac{n+1}{2})} h≈log2​(2n+1​)\n",
    "\n",
    "One adjustment: Consider a perfect, 2-level tree. There are 2 levels overall, but the \"number of times we have to double 1 to get to 2\" is just 1. Our height is in fact one more than our number of doublings. So we add 1:\n",
    "h=log⁡2(n+12)+1 h = \\log_{2}{(\\frac{n+1}{2})} + 1 h=log2​(2n+1​)+1\n",
    "\n",
    "We can apply some of our logarithm rules to simplify this:\n",
    "h=log⁡2(n+12)+1 h = \\log_{2}{(\\frac{n+1}{2})} + 1 h=log2​(2n+1​)+1 h=log⁡2(n+1)−log⁡2(2)+1 h = \\log_{2}{(n+1)} - \\log_{2}{(2)} + 1 h=log2​(n+1)−log2​(2)+1 h=log⁡2(n+1)−1+1 h = \\log_{2}{(n+1)} - 1 + 1 h=log2​(n+1)−1+1 h=log⁡2(n+1) h = \\log_{2}{(n+1)} h=log2​(n+1)\n",
    "Conventions with bases\n",
    "\n",
    "Sometimes people don't include a base. In computer science, it's usually implied that the base is 2. So log⁡n\\log{n}logn generally means log⁡2n\\log_{2}{n}log2​n.\n",
    "\n",
    "Some folks might remember that in most other maths, an unspecified base is implied to be 10. Or sometimes the special constant eee. (Don't worry if you don't know what eee is.)\n",
    "\n",
    "There's a specific notation for log base 2 that's sometimes used: lg⁡\\lglg. So we could say lg⁡n\\lg{n}lgn, or nlg⁡nn\\lg{n}nlgn (which comes up a lot in sorting). We use this notation a lot on Interview Cake, but it's worth noting that not everyone uses it.\n",
    "\n",
    "Some folks might know there's a similar-ish specific notation for log base eee: ln⁡\\lnln (pronounced \"natural log\").\n",
    "\n",
    "In big O notation the base is considered a constant. So folks usually don't include it. People usually say O(log⁡n)O(\\log{n})O(logn), not O(log⁡2n)O(\\log_{2}{n})O(log2​n),\n",
    "\n",
    "But people might still use the special notation lg⁡n\\lg{n}lgn, as in O(lg⁡n)O(\\lg{n})O(lgn). It saves us from having to write an \"o\" :) \n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
